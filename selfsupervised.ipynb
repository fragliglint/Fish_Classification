{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eedcb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU: NVIDIA RTX A4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU not found. Training will run on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ebb3253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightly\n",
      "  Downloading lightly-1.5.21-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly) (2025.6.15)\n",
      "Collecting hydra-core>=1.0.0 (from lightly)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lightly_utils~=0.0.0 (from lightly)\n",
      "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly) (2.1.2)\n",
      "Requirement already satisfied: python_dateutil>=2.5.3 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.27.0 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly) (2.32.4)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly) (1.17.0)\n",
      "Collecting tqdm>=4.44 (from lightly)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly) (2.7.1+cu128)\n",
      "Requirement already satisfied: torchvision in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly) (0.22.1+cu128)\n",
      "Collecting pydantic>=1.10.5 (from lightly)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pytorch_lightning>=1.0.4 (from lightly)\n",
      "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly) (2.5.0)\n",
      "Collecting aenum>=3.1.11 (from lightly)\n",
      "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightly_utils~=0.0.0->lightly) (11.0.0)\n",
      "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: packaging in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from hydra-core>=1.0.0->lightly) (25.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.0.0->lightly) (6.0.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=1.10.5->lightly)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=1.10.5->lightly)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from pydantic>=1.10.5->lightly) (4.14.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=1.10.5->lightly)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2024.6.1)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading aiohttp-3.12.14-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading multidict-6.6.3-cp310-cp310-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (3.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch_lightning>=1.0.4->lightly) (78.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from requests>=2.27.0->lightly) (3.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from torch->lightly) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from torch->lightly) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from torch->lightly) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from torch->lightly) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from sympy>=1.13.3->torch->lightly) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from tqdm>=4.44->lightly) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from jinja2->torch->lightly) (3.0.2)\n",
      "Downloading lightly-1.5.21-py3-none-any.whl (855 kB)\n",
      "   ---------------------------------------- 0.0/855.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 855.8/855.8 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
      "Downloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "   ---------------------------------------- 0.0/825.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 825.4/825.4 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.12.14-cp310-cp310-win_amd64.whl (451 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-win_amd64.whl (45 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-win_amd64.whl (43 kB)\n",
      "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-win_amd64.whl (41 kB)\n",
      "Downloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
      "   ---------------------------------------- 0.0/963.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 963.5/963.5 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144614 sha256=3e7dc80607455e389633f5fbcc2c62a883e7641a407fe654a28e03038788beb7\n",
      "  Stored in directory: c:\\users\\student\\appdata\\local\\pip\\cache\\wheels\\12\\93\\dd\\1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, aenum, typing-inspection, tqdm, pydantic-core, propcache, omegaconf, multidict, lightning-utilities, lightly_utils, frozenlist, async-timeout, annotated-types, aiohappyeyeballs, yarl, pydantic, hydra-core, aiosignal, torchmetrics, aiohttp, pytorch_lightning, lightly\n",
      "\n",
      "   - --------------------------------------  1/22 [aenum]\n",
      "   ----- ----------------------------------  3/22 [tqdm]\n",
      "   ---------- -----------------------------  6/22 [omegaconf]\n",
      "   ------------------------- -------------- 14/22 [yarl]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   ----------------------------- ---------- 16/22 [hydra-core]\n",
      "   ----------------------------- ---------- 16/22 [hydra-core]\n",
      "   -------------------------------- ------- 18/22 [torchmetrics]\n",
      "   -------------------------------- ------- 18/22 [torchmetrics]\n",
      "   -------------------------------- ------- 18/22 [torchmetrics]\n",
      "   -------------------------------- ------- 18/22 [torchmetrics]\n",
      "   ---------------------------------- ----- 19/22 [aiohttp]\n",
      "   ------------------------------------ --- 20/22 [pytorch_lightning]\n",
      "   ------------------------------------ --- 20/22 [pytorch_lightning]\n",
      "   ------------------------------------ --- 20/22 [pytorch_lightning]\n",
      "   ------------------------------------ --- 20/22 [pytorch_lightning]\n",
      "   -------------------------------------- - 21/22 [lightly]\n",
      "   -------------------------------------- - 21/22 [lightly]\n",
      "   -------------------------------------- - 21/22 [lightly]\n",
      "   -------------------------------------- - 21/22 [lightly]\n",
      "   -------------------------------------- - 21/22 [lightly]\n",
      "   ---------------------------------------- 22/22 [lightly]\n",
      "\n",
      "Successfully installed aenum-3.1.16 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 async-timeout-5.0.1 frozenlist-1.7.0 hydra-core-1.3.2 lightly-1.5.21 lightly_utils-0.0.2 lightning-utilities-0.14.3 multidict-6.6.3 omegaconf-2.3.0 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 pytorch_lightning-2.5.2 torchmetrics-1.7.4 tqdm-4.67.1 typing-inspection-0.4.1 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'antlr4-python3-runtime' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "pip install lightly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba17b8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU: NVIDIA RTX A4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\.conda\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Student\\.conda\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Student\\.conda\\envs\\torch-gpu\\lib\\site-packages\\lightly\\models\\simclr.py:39: Warning: The high-level building block SimCLR will be deprecated in version 1.3.0. Use low-level building blocks instead. See https://docs.lightly.ai/self-supervised-learning/lightly.models.html for more information\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimCLR model loaded and moved to cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from lightly.models import SimCLR\n",
    "\n",
    "# === Step 1: Check GPU\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Step 2: Build ResNet backbone without final classification layer\n",
    "resnet = resnet18(pretrained=False)\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])  # Remove final FC layer\n",
    "\n",
    "# === Step 3: Load SimCLR model\n",
    "model = SimCLR(backbone, num_ftrs=512, out_dim=128)\n",
    "model.to(device)\n",
    "\n",
    "print(\"SimCLR model loaded and moved to\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4805da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.0-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.6/10.7 MB 10.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/10.7 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/10.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/10.7 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.9/10.7 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/10.7 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/10.7 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.8/10.7 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.0/10.7 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.6/10.7 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.1/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.6/10.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.1/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.7/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.9/10.7 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.4/10.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.0/10.7 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.7 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/41.3 MB 4.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.3/41.3 MB 4.0 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.8/41.3 MB 3.5 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.4/41.3 MB 3.0 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 2.9/41.3 MB 2.9 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 3.4/41.3 MB 3.0 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 3.9/41.3 MB 2.7 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 4.7/41.3 MB 2.9 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 5.0/41.3 MB 2.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 5.5/41.3 MB 2.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 6.0/41.3 MB 2.7 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 6.6/41.3 MB 2.7 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 7.3/41.3 MB 2.7 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 8.4/41.3 MB 2.9 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 8.9/41.3 MB 2.8 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 9.4/41.3 MB 2.9 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 10.0/41.3 MB 2.8 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 10.2/41.3 MB 2.7 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 10.7/41.3 MB 2.7 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 11.0/41.3 MB 2.7 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 11.8/41.3 MB 2.7 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 12.3/41.3 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 12.6/41.3 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 13.1/41.3 MB 2.6 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 13.6/41.3 MB 2.6 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 14.2/41.3 MB 2.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 14.7/41.3 MB 2.6 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 15.2/41.3 MB 2.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 15.7/41.3 MB 2.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 16.3/41.3 MB 2.6 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 16.8/41.3 MB 2.6 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 17.0/41.3 MB 2.6 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 17.6/41.3 MB 2.6 MB/s eta 0:00:10\n",
      "   ------------------ --------------------- 18.6/41.3 MB 2.6 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 19.1/41.3 MB 2.6 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 19.4/41.3 MB 2.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 19.9/41.3 MB 2.6 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 20.4/41.3 MB 2.6 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 21.0/41.3 MB 2.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 21.5/41.3 MB 2.6 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 22.0/41.3 MB 2.6 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 22.8/41.3 MB 2.6 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 23.3/41.3 MB 2.6 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 23.9/41.3 MB 2.6 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 24.4/41.3 MB 2.6 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 24.9/41.3 MB 2.6 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 25.7/41.3 MB 2.6 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 26.2/41.3 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 26.5/41.3 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 26.7/41.3 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 27.3/41.3 MB 2.6 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 27.8/41.3 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 28.3/41.3 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 29.1/41.3 MB 2.6 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 29.9/41.3 MB 2.6 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 30.7/41.3 MB 2.6 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 31.2/41.3 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 31.7/41.3 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 32.2/41.3 MB 2.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 33.0/41.3 MB 2.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 33.6/41.3 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.1/41.3 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.6/41.3 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 35.1/41.3 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 35.7/41.3 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 36.4/41.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 37.0/41.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.5/41.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.7/41.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 38.0/41.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 38.3/41.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 39.1/41.3 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.6/41.3 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 40.1/41.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.6/41.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   ---------- ----------------------------- 1/4 [scipy]\n",
      "   -------------------- ------------------- 2/4 [joblib]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e07a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Total images: 26950 (train 18865, val 4042, test 4043)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Paths\n",
    "# ------------------------------------------------------------------\n",
    "SRC_ROOT  = r'E:\\dish dataset\\Fish Data'       # original root with class folders\n",
    "DEST_ROOT = r'E:\\dish dataset\\Fish Data Split' # new flat split\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Split ratios\n",
    "# ------------------------------------------------------------------\n",
    "TRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.70, 0.15, 0.15   # must sum to 1\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Make destination folders\n",
    "# ------------------------------------------------------------------\n",
    "for split in ('train', 'val', 'test'):\n",
    "    os.makedirs(os.path.join(DEST_ROOT, split), exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Collect *all* image paths, ignoring sub‑folder (class) names\n",
    "# ------------------------------------------------------------------\n",
    "all_images = []\n",
    "for class_name in os.listdir(SRC_ROOT):\n",
    "    class_path = os.path.join(SRC_ROOT, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    for root, _, files in os.walk(class_path):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
    "                all_images.append(os.path.join(root, f))\n",
    "\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Determine split indices\n",
    "# ------------------------------------------------------------------\n",
    "n_total   = len(all_images)\n",
    "n_train   = int(TRAIN_RATIO * n_total)\n",
    "n_val     = int(VAL_RATIO   * n_total)\n",
    "# everything else → test\n",
    "train_imgs = all_images[:n_train]\n",
    "val_imgs   = all_images[n_train:n_train + n_val]\n",
    "test_imgs  = all_images[n_train + n_val:]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Helper to copy while avoiding name collisions\n",
    "# ------------------------------------------------------------------\n",
    "def flat_copy(src_paths, split_name):\n",
    "    dest_folder = os.path.join(DEST_ROOT, split_name)\n",
    "    for src in tqdm(src_paths, desc=f'Copying {split_name}', leave=False):\n",
    "        # If different classes share filenames, make them unique\n",
    "        basename = os.path.basename(src)\n",
    "        dest     = os.path.join(dest_folder, basename)\n",
    "\n",
    "        # If the name already exists, append a unique suffix\n",
    "        if os.path.exists(dest):\n",
    "            stem, ext = os.path.splitext(basename)\n",
    "            dest = os.path.join(dest_folder, f'{stem}_{uuid.uuid4().hex[:8]}{ext}')\n",
    "\n",
    "        shutil.copy(src, dest)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. Perform the copies\n",
    "# ------------------------------------------------------------------\n",
    "flat_copy(train_imgs, 'train')\n",
    "flat_copy(val_imgs,   'val')\n",
    "flat_copy(test_imgs,  'test')\n",
    "\n",
    "print(f'✅ Done! Total images: {n_total} '\n",
    "      f'(train {len(train_imgs)}, val {len(val_imgs)}, test {len(test_imgs)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1a241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\.conda\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/10 - Loss: 3.6113\n",
      "Epoch 2/10 - Loss: 3.1203\n",
      "Epoch 3/10 - Loss: 2.9627\n",
      "Epoch 4/10 - Loss: 2.8771\n",
      "Epoch 5/10 - Loss: 2.8238\n",
      "Checkpoint saved to E:\\dish dataset\\checkpoints\\simclr_epoch_5.pth\n",
      "Epoch 6/10 - Loss: 2.7868\n",
      "Epoch 7/10 - Loss: 2.7587\n",
      "Epoch 8/10 - Loss: 2.7289\n",
      "Epoch 9/10 - Loss: 2.7141\n",
      "Epoch 10/10 - Loss: 2.6858\n",
      "Checkpoint saved to E:\\dish dataset\\checkpoints\\simclr_epoch_10.pth\n",
      "✅ Pretraining Complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.data.collate import SimCLRCollateFunction\n",
    "from lightly.models import SimCLR\n",
    "from lightly.loss import NTXentLoss\n",
    "from torchvision.models import resnet18\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "dataset_path = r'E:\\dish dataset\\Fish Data Split\\train'\n",
    "checkpoint_dir = r'E:\\dish dataset\\checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = LightlyDataset(input_dir=dataset_path)\n",
    "collate_fn = SimCLRCollateFunction(input_size=224)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
    "\n",
    "# Model: ResNet18 backbone without final FC\n",
    "resnet = resnet18(pretrained=False)\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])  # remove last fc layer\n",
    "model = SimCLR(backbone, num_ftrs=512, out_dim=128)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = NTXentLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for (x0, x1), _, _ in dataloader:\n",
    "        x0, x1 = x0.to(device), x1.to(device)\n",
    "        z0, z1 = model(x0), model(x1)\n",
    "        loss = criterion(z0, z1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save checkpoint every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"simclr_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "print(\"✅ Pretraining Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075d3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\student\\.conda\\envs\\torch-gpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.3 MB 6.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/11.3 MB 9.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.3 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.3 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d79b9934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\.conda\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Student\\.conda\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\Student/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 20  # Your 20 fish classes\n",
    "\n",
    "# Load pretrained ResNet18 backbone\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# Replace the final FC layer to match your classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24497dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Optional learning rate scheduler:\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1dfb3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df8aa031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Class distribution:\n",
      " label\n",
      "14    1743\n",
      "16    1564\n",
      "18    1438\n",
      "10    1264\n",
      "0     1255\n",
      "11    1221\n",
      "7     1218\n",
      "1     1174\n",
      "13    1104\n",
      "19    1015\n",
      "15     995\n",
      "17     890\n",
      "5      713\n",
      "12     673\n",
      "6      640\n",
      "8      582\n",
      "4      391\n",
      "9      387\n",
      "2      302\n",
      "3      296\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\.conda\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Student\\.conda\\envs\\torch-gpu\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "|Train Loss: 0.5286 | Train Acc: 0.8640 | Val Loss: 0.0679 | Val Acc: 0.9828|\n",
      "✅ Best model saved.\n",
      "Epoch [2/10]\n",
      "|Train Loss: 0.0702 | Train Acc: 0.9839 | Val Loss: 0.0250 | Val Acc: 0.9931|\n",
      "✅ Best model saved.\n",
      "Epoch [3/10]\n",
      "|Train Loss: 0.0412 | Train Acc: 0.9906 | Val Loss: 0.0167 | Val Acc: 0.9958|\n",
      "✅ Best model saved.\n",
      "Epoch [4/10]\n",
      "|Train Loss: 0.0279 | Train Acc: 0.9934 | Val Loss: 0.0133 | Val Acc: 0.9966|\n",
      "✅ Best model saved.\n",
      "Epoch [5/10]\n",
      "|Train Loss: 0.0304 | Train Acc: 0.9920 | Val Loss: 0.0398 | Val Acc: 0.9886|\n",
      "Epoch [6/10]\n",
      "|Train Loss: 0.0092 | Train Acc: 0.9987 | Val Loss: 0.0037 | Val Acc: 0.9992|\n",
      "✅ Best model saved.\n",
      "Epoch [7/10]\n",
      "|Train Loss: 0.0065 | Train Acc: 0.9991 | Val Loss: 0.0054 | Val Acc: 0.9984|\n",
      "Epoch [8/10]\n",
      "|Train Loss: 0.0054 | Train Acc: 0.9992 | Val Loss: 0.0061 | Val Acc: 0.9976|\n",
      "Epoch [9/10]\n",
      "|Train Loss: 0.0083 | Train Acc: 0.9983 | Val Loss: 0.0059 | Val Acc: 0.9981|\n",
      "Epoch [10/10]\n",
      "|Train Loss: 0.0095 | Train Acc: 0.9976 | Val Loss: 0.0103 | Val Acc: 0.9958|\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === STEP 1: Paths ===\n",
    "img_dir = r\"E:\\dish dataset\\Fish Data Split\\train\"\n",
    "csv_path = os.path.join(img_dir, \"train_labels.csv\")\n",
    "\n",
    "# === STEP 2: Check Class Balance ===\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"📊 Class distribution:\\n\", df['label'].value_counts())\n",
    "\n",
    "# === STEP 3: Transformations ===\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# === STEP 4: Custom Dataset ===\n",
    "class FishDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx, 0]\n",
    "        label = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# === STEP 5: Load Data and Split ===\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "train_df.to_csv(\"train_split.csv\", index=False)\n",
    "val_df.to_csv(\"val_split.csv\", index=False)\n",
    "\n",
    "train_dataset = FishDataset(\"train_split.csv\", img_dir, transform=train_transform)\n",
    "val_dataset = FishDataset(\"val_split.csv\", img_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# === STEP 6: Define Model ===\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(model.fc.in_features, 20)  # 20 classes\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "# === STEP 7: Training Setup ===\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# === STEP 8: Training and Validation Functions ===\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct = 0.0, 0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = correct / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = correct / len(dataloader.dataset)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# === STEP 9: Train Loop ===\n",
    "device = 0  # GPU only\n",
    "num_epochs = 10\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"|Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}|\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_fish_model.pth\")\n",
    "        print(\"✅ Best model saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6793bfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Best Validation Accuracy: 99.92%\n"
     ]
    }
   ],
   "source": [
    "print(f\"📈 Best Validation Accuracy: {best_val_acc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
